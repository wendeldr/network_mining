{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.special import softmax \n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"F:/git/eeg_prep/processed_files/039_000500_000500.hdf5\"\n",
    "path = \"/media/dan/Data/git/eeg_prep/processed_files/098_000500_000500.hdf5\"\n",
    "with h5py.File(path, \"r\") as f:\n",
    "    A_mats_500 = f['data']['A_mats'][:]\n",
    "    A_mats_500_mask = f['data']['A_mask'][:]\n",
    "    soz = f['metadata'][\"patient_info\"]['soz'][:].astype(bool)\n",
    "    chnames = f['metadata']['channels'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple embedding model\n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim=256):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.fc1 = nn.Linear(input_dim, self.hidden_dim)\n",
    "        self.fc2 = nn.Linear(self.hidden_dim, embedding_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # Embedding output (no activation for embeddings)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 140, 542)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = A_mats_500[:,:,A_mats_500_mask==1]\n",
    "A = np.abs(A)\n",
    "eye = np.eye(A.shape[0]) == 1\n",
    "A[eye,:] = np.nan\n",
    "# normalize 0-1 for each row so each row at each time point is 0-1 \n",
    "for time in range(A.shape[-1]):\n",
    "    # Get the 2D matrix at the specific time step\n",
    "    slice_t = A[:, :, time]\n",
    "    \n",
    "    # Normalize each row individually\n",
    "    row_min = np.nanmin(slice_t, axis=1, keepdims=True)\n",
    "    row_max = np.nanmax(slice_t, axis=1, keepdims=True)\n",
    "    \n",
    "    # Avoid division by zero in case of zero-variance rows\n",
    "    normalized_slice = (slice_t - row_min) / (row_max - row_min + 1e-10)\n",
    "    \n",
    "    # Place the normalized slice back into A\n",
    "    A[:, :, time] = normalized_slice\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "input_dim = X.shape[1]  # Dimension of each vector (C)\n",
    "embedding_dim = 2       # Low-dimensional embedding for clustering\n",
    "\n",
    "model = EmbeddingNet(input_dim, embedding_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sourcesink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
