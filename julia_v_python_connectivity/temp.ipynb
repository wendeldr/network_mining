{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using FFTW\n",
    "using Statistics\n",
    "using JLD2\n",
    "using NPZ\n",
    "using ProgressMeter\n",
    "# using BenchmarkTools\n",
    "\n",
    "function sinusoidal(a, f, sr, t, theta=0, DC=0)\n",
    "    delta_i = 1 / sr\n",
    "    f2pi = f * 2 * ฯ\n",
    "    nu = [DC + (a * sin(f2pi * i * delta_i + theta)) for i in 0:(t-1)]\n",
    "    return nu\n",
    "end\n",
    "\n",
    "function tfr_estimate_size(n_epochs, n_channels, n_taps, n_freqs, n_times)\n",
    "    element_size = 16 # bytes for ComplexF64\n",
    "    total_elements = n_epochs * n_channels * n_taps * n_freqs * n_times\n",
    "    total_bytes = total_elements * element_size\n",
    "    total_gb = total_bytes / (1024^3) # Convert bytes to GB\n",
    "    return total_gb\n",
    "end\n",
    "\n",
    "function weights_estimate_size(n_taps, n_freqs, n_times)\n",
    "    element_size = 8 # bytes for Float64\n",
    "    total_elements = n_taps * n_freqs * n_times\n",
    "    total_bytes = total_elements * element_size\n",
    "    total_gb = total_bytes / (1024^3) # Convert bytes to GB\n",
    "    return total_gb\n",
    "end\n",
    "\n",
    "function Ws_estimate_size(n_taps, freqs, sfreq, n_cycles)\n",
    "    element_size = 16 # bytes for ComplexF64\n",
    "    total_elements = 0\n",
    "    for k = 1:n_freqs\n",
    "        f = freqs[k]\n",
    "        t_win = n_cycles / f\n",
    "        len_t = Int(ceil(t_win * sfreq))\n",
    "        total_elements += n_taps * len_t\n",
    "    end\n",
    "    total_bytes = total_elements * element_size\n",
    "    total_gb = total_bytes / (1024^3) # Convert bytes to GB\n",
    "    return total_gb\n",
    "end\n",
    "\n",
    "function fft_estimate_size(a, b, c)\n",
    "    element_size = 16 # bytes for ComplexF64\n",
    "    total_elements = a * b * c\n",
    "    total_bytes = total_elements * element_size\n",
    "    total_gb = total_bytes / (1024^3) # Convert bytes to GB\n",
    "    return total_gb\n",
    "end\n",
    "\n",
    "function psd_estimate_size(n_epochs, n_channels, n_freqs, n_times)\n",
    "    element_size = 8 # bytes for Float64\n",
    "    total_elements = n_epochs * n_channels * n_freqs * n_times\n",
    "    total_bytes = total_elements * element_size\n",
    "    total_gb = total_bytes / (1024^3) # Convert bytes to GB\n",
    "    return total_gb\n",
    "end\n",
    "\n",
    "function coh_estimate_size(n_epochs, n_channels, n_freqs)\n",
    "    element_size = 8 # bytes for Float64\n",
    "    total_elements = n_epochs * n_channels * n_channels * n_freqs\n",
    "    total_bytes = total_elements * element_size\n",
    "    total_gb = total_bytes / (1024^3) # Convert bytes to GB\n",
    "    return total_gb\n",
    "end\n",
    "\n",
    "function scale_dimensions(data, n_taps, freqs, sfreq, n_cycles; print=false, max_gb=0, reserve_gb=0)\n",
    "    system_mem = Sys.total_memory() / (1024^3)\n",
    "    if max_gb == 0\n",
    "        max_gb =  system_mem- reserve_gb # Leave X GB for other stuff\n",
    "    end\n",
    "    current_mem = Sys.free_memory() / (1024^3)\n",
    "    if current_mem <= max_gb\n",
    "        @warn \"Current free memory: $current_mem GB\\nDesired max: $max_gb GB\\nSystem total memory: $(system_mem) GB\\nMemory available is less than desired max!\\nAttempting to use available memory!\"\n",
    "        max_gb = current_mem - reserve_gb\n",
    "    end\n",
    "    if(max_gb <= 0)\n",
    "        error(\"Not enough memory available!\")\n",
    "    end\n",
    "    \n",
    "    n_epoch_org, n_channels, n_times = size(data)\n",
    "\n",
    "    n_freqs = length(freqs)\n",
    "    t_win = n_cycles / minimum(freqs)\n",
    "    max_len = Int(ceil(t_win * sfreq))\n",
    "    nfft = n_times + max_len - 1\n",
    "    nfft = next_fast_len(nfft)\n",
    "    \n",
    "    data_size = Base.summarysize(data) / (1024^3)\n",
    "    weights = weights_estimate_size(n_taps, n_freqs, n_times)\n",
    "    Ws = Ws_estimate_size(n_taps, freqs, sfreq, n_cycles)\n",
    "    fft_Ws = fft_estimate_size(n_taps, n_freqs, nfft)\n",
    "    fft_X = fft_estimate_size(n_epoch_org, n_channels, nfft)\n",
    "    coherence_mean = coh_estimate_size(n_epoch_org, n_channels, 1)\n",
    "    \n",
    "    current_mem = Sys.free_memory() / (1024^3)\n",
    "    \n",
    "    static_total = data_size + weights + Ws + fft_Ws + fft_X + coherence_mean\n",
    "    \n",
    "    if static_total >= max_gb || static_total >= current_mem\n",
    "        println(\"Static calculations will exceed memory!\")\n",
    "        println(\"---------------------------------\")\n",
    "        println(\"Current free memory: $current_mem GB\")\n",
    "        println(\"---------------------------------\")\n",
    "        println(\"Data: $(data_size) GB\")\n",
    "        println(\"Weights: $weights GB\")\n",
    "        println(\"Ws: $Ws GB\")\n",
    "        println(\"FFT Ws: $fft_Ws GB\")\n",
    "        println(\"FFT X: $fft_X GB\")\n",
    "        println(\"Coherence Mean: $coherence_mean GB\")\n",
    "        println(\"---------------------------------\")\n",
    "        println(\"Total: $static_total GB\")\n",
    "        println(\"Exceeds maximum memory limit of $max_gb GB or current free memory\")\n",
    "        error(\"Memory limit exceeded\")\n",
    "    end\n",
    "    n_epochs = copy(n_epoch_org)\n",
    "    tfr_size = tfr_estimate_size(n_epochs, n_channels, n_taps, n_freqs, n_times)\n",
    "    psd_per_epoch = psd_estimate_size(n_epochs, n_channels, n_freqs, n_times)\n",
    "    coherence = coh_estimate_size(n_epoch_org, n_channels, n_freqs)\n",
    "    coherence_mean_small = 0\n",
    "    \n",
    "    dynamic_total = tfr_size + psd_per_epoch + coherence + coherence_mean_small    \n",
    "    while dynamic_total + static_total >= max_gb && n_epochs > 0\n",
    "        n_epochs -= 1\n",
    "        tfr_size = tfr_estimate_size(n_epochs, n_channels, n_taps, n_freqs, n_times)\n",
    "        psd_per_epoch = psd_estimate_size(n_epochs, n_channels, n_freqs, n_times)\n",
    "        coherence = coh_estimate_size(n_epochs, n_channels, n_freqs)\n",
    "        coherence_mean_small = coh_estimate_size(n_epochs, n_channels, 1)\n",
    "        dynamic_total = tfr_size + psd_per_epoch + coherence + coherence_mean_small\n",
    "    end\n",
    "\n",
    "    if n_epochs == 0\n",
    "        current_mem = Sys.free_memory() / (1024^3)\n",
    "        println(\"Can not even compute one epoch with current memory!\")\n",
    "        println(\"---------------------------------\")\n",
    "        println(\"Current free memory: $current_mem GB\")\n",
    "        println(\"System total memory: $system_mem GB\")\n",
    "        println(\"--------------Static arrays--------------\")\n",
    "        println(\"Data: $(data_size) GB\")\n",
    "        println(\"Weights: $weights GB\")\n",
    "        println(\"Ws: $Ws GB\")\n",
    "        println(\"FFT Ws: $fft_Ws GB\")\n",
    "        println(\"FFT X: $fft_X GB\")\n",
    "        println(\"Coherence Mean: $coherence_mean GB\")\n",
    "        println(\"Static Total: $static_total GB\")\n",
    "        println(\"-----Dynamically calculated arrays-----\")\n",
    "        println(\"TFR: $tfr_size GB\")\n",
    "        println(\"PSD: $psd_per_epoch GB\")\n",
    "        println(\"Coherence: $coherence GB\")\n",
    "        println(\"Coherence Mean (small): $coherence_mean_small GB\")\n",
    "        println(\"Dynamic Total: $dynamic_total GB\")\n",
    "        println(\"---------------------------------\")\n",
    "        println(\"Total: $dynamic_total + $static_total GB\")\n",
    "        println(\"Exceeds maximum memory limit of $max_gb GB\")\n",
    "        error(\"Memory limit exceeded\")\n",
    "    end\n",
    "\n",
    "\n",
    "\n",
    "    if print\n",
    "        current_mem = Sys.free_memory() / (1024^3)\n",
    "        println(\"Can be computed with batches of $n_epochs epochs\")\n",
    "        println(\"total batches: $(ceil(n_epoch_org/n_epochs))\")\n",
    "        println(\"--------------Static arrays--------------\")\n",
    "        println(\"Data: $(data_size) GB\")\n",
    "        println(\"Weights: $weights GB\")\n",
    "        println(\"Ws: $Ws GB\")\n",
    "        println(\"FFT Ws: $fft_Ws GB\")\n",
    "        println(\"FFT X: $fft_X GB\")\n",
    "        println(\"Coherence Mean: $coherence_mean GB\")\n",
    "        println(\"Static Total: $static_total GB\")\n",
    "        println(\"-----Dynamically calculated arrays-----\")\n",
    "        println(\"TFR: $tfr_size GB\")\n",
    "        println(\"PSD: $psd_per_epoch GB\")\n",
    "        println(\"Coherence: $coherence GB\")\n",
    "        println(\"Coherence Mean (small): $coherence_mean_small GB\")\n",
    "        println(\"Dynamic Total: $dynamic_total GB\")\n",
    "        println(\"---------------------------------\")\n",
    "        println(\"Total: $(dynamic_total+static_total) GB\")\n",
    "        println(\"Desired max: $max_gb GB\")\n",
    "        println(\"---------------------------------\")        \n",
    "        println(\"Current free memory: $current_mem GB\")\n",
    "        println(\"System total memory: $system_mem GB\")\n",
    "    end\n",
    "    return n_epochs\n",
    "end\n",
    "\n",
    "\n",
    "function tril_indices(n)::Array{Tuple{Int,Int},1}\n",
    "    pairs = Array{Tuple{Int,Int},1}(undef, n * (n - 1) รท 2)\n",
    "    q = 1\n",
    "    for x in 1:n\n",
    "        for y in (x+1):n\n",
    "            pairs[q] = (x, y)\n",
    "            q += 1\n",
    "        end\n",
    "    end\n",
    "    return pairs\n",
    "end\n",
    "\n",
    "\n",
    "function next_fast_len(target::Int)::Int\n",
    "    \"\"\"\n",
    "    Find the next fast size of input data to `fft`, for zero-padding, etc.\n",
    "\n",
    "    Returns the next composite of the prime factors 2, 3, and 5 which is\n",
    "    greater than or equal to `target`. (These are also known as 5-smooth\n",
    "    numbers, regular numbers, or Hamming numbers.)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Int\n",
    "        Length to start searching from. Must be a positive integer.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : Int\n",
    "        The first 5-smooth number greater than or equal to `target`.\n",
    "    \"\"\"\n",
    "    # Precomputed Hamming numbers (5-smooth numbers) for quick lookup\n",
    "    hams = [\n",
    "        8, 9, 10, 12, 15, 16, 18, 20, 24, 25, 27, 30, 32, 36, 40, 45, 48, 50,\n",
    "        54, 60, 64, 72, 75, 80, 81, 90, 96, 100, 108, 120, 125, 128, 135, 144,\n",
    "        150, 160, 162, 180, 192, 200, 216, 225, 240, 243, 250, 256, 270, 288,\n",
    "        300, 320, 324, 360, 375, 384, 400, 405, 432, 450, 480, 486, 500, 512,\n",
    "        540, 576, 600, 625, 640, 648, 675, 720, 729, 750, 768, 800, 810, 864,\n",
    "        900, 960, 972, 1000, 1024, 1080, 1125, 1152, 1200, 1215, 1250, 1280,\n",
    "        1296, 1350, 1440, 1458, 1500, 1536, 1600, 1620, 1728, 1800, 1875, 1920,\n",
    "        1944, 2000, 2025, 2048, 2160, 2187, 2250, 2304, 2400, 2430, 2500, 2560,\n",
    "        2592, 2700, 2880, 2916, 3000, 3072, 3125, 3200, 3240, 3375, 3456, 3600,\n",
    "        3645, 3750, 3840, 3888, 4000, 4050, 4096, 4320, 4374, 4500, 4608, 4800,\n",
    "        4860, 5000, 5120, 5184, 5400, 5625, 5760, 5832, 6000, 6075, 6144, 6250,\n",
    "        6400, 6480, 6561, 6750, 6912, 7200, 7290, 7500, 7680, 7776, 8000, 8100,\n",
    "        8192, 8640, 8748, 9000, 9216, 9375, 9600, 9720, 10000\n",
    "    ]\n",
    "\n",
    "    if target <= 6\n",
    "        return target\n",
    "    end\n",
    "\n",
    "    # Check if target is already a power of 2\n",
    "    if (target & (target - 1)) == 0\n",
    "        return target\n",
    "    end\n",
    "\n",
    "    # Quick lookup for small sizes\n",
    "    if target <= hams[end]\n",
    "        idx = searchsortedfirst(hams, target)\n",
    "        return hams[idx]\n",
    "    end\n",
    "\n",
    "    # Function to compute the bit length of an integer\n",
    "    bit_length(x::Int) = x <= 0 ? 0 : floor(Int, log2(x)) + 1\n",
    "\n",
    "    match = typemax(Int)  # Initialize with maximum possible integer\n",
    "    p5 = 1\n",
    "    while p5 < target\n",
    "        p35 = p5\n",
    "        while p35 < target\n",
    "            # Ceiling integer division\n",
    "            quotient = cld(target, p35)\n",
    "            p2 = 2^bit_length(quotient - 1)\n",
    "            N = p2 * p35\n",
    "            if N == target\n",
    "                return N\n",
    "            elseif N < match\n",
    "                match = N\n",
    "            end\n",
    "            p35 *= 3\n",
    "            if p35 == target\n",
    "                return p35\n",
    "            end\n",
    "        end\n",
    "        if p35 < match\n",
    "            match = p35\n",
    "        end\n",
    "        p5 *= 5\n",
    "        if p5 == target\n",
    "            return p5\n",
    "        end\n",
    "    end\n",
    "    if p5 < match\n",
    "        match = p5\n",
    "    end\n",
    "    return match\n",
    "end\n",
    "\n",
    "\n",
    "outputpath = \"/media/dan/Data/git/network_mining/connectivity/julia_test/\"\n",
    "data = npzread(\"/media/dan/Data/git/network_mining/connectivity/julia_test/034_input.npy\")\n",
    "data = data[1:2, 1:10, :]\n",
    "\n",
    "sfreq = 2048\n",
    "freqs = collect(14:50)\n",
    "zero_mean = true\n",
    "n_freqs = length(freqs)\n",
    "mt_bandwidth = 4\n",
    "n_taps = floor(Int, mt_bandwidth - 1)\n",
    "n_cycles = 7\n",
    "n_epochs, n_channels, n_times = size(data)\n",
    "\n",
    "batch_size = scale_dimensions(data, n_taps, freqs, sfreq, n_cycles, print=true, reserve_gb=60)\n",
    "total_batches = ceil(n_epochs / batch_size)\n",
    "if batch_size != n_epochs\n",
    "    println(\"Data is too big for one pass!\\nData will be computed in batches of $batch_size epochs. Total batches: $(total_batches)\")\n",
    "end\n",
    "\n",
    "\n",
    "println(\"Making tapers...\")\n",
    "Ws, weights = compute_tapers(n_times, n_taps, freqs, mt_bandwidth, n_cycles, sfreq)\n",
    "weights_squared = weights .^ 2\n",
    "normalization = 2 ./ sum(real(weights .* conj(weights)), dims=1);\n",
    "small_norm = dropdims(normalization; dims=1)\n",
    "\n",
    "nfft = _get_nfft(Ws, data)\n",
    "\n",
    "println(\"Precomputing FFTs of tapers and data...\")\n",
    "fft_Ws = precompute_fft_Ws(Ws, nfft);\n",
    "fft_X = precompute_fft_X(data, nfft);\n",
    "println(\"Done!\")\n",
    "\n",
    "# save(joinpath(outputpath, \"034_pretasks.jld2\"), \"Ws\", Ws, \"weights\", weights, \"fft_Ws\", fft_Ws, \"fft_X\", fft_X, \"normalization\", normalization)\n",
    "\n",
    "Ws_lengths = [length(Wk) for Wk in Ws]\n",
    "\n",
    "println(\"Preparing for computation...\")\n",
    "pairs = tril_indices(n_channels)\n",
    "n_pairs = length(pairs)\n",
    "\n",
    "\n",
    "tfr = Array{ComplexF64,5}(undef, batch_size, n_channels, n_taps, n_freqs, n_times);\n",
    "compute_tfr!(tfr, fft_X, fft_Ws, Ws_lengths);\n",
    "\n",
    "psd_per_epoch = Array{Float64,4}(undef, batch_size, n_channels, n_freqs, n_times);\n",
    "compute_psd!(psd_per_epoch, tfr, weights, small_norm);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can be computed with batches of 152 epochs\n",
      "total batches: 4.0\n",
      "--------------Static arrays--------------\n",
      "Data: 0.4484711214900017 GB\n",
      "Weights: 0.00542449951171875 GB\n",
      "Ws: 0.0018763840198516846 GB\n",
      "FFT Ws: 0.021697998046875 GB\n",
      "FFT X: 1.79388427734375 GB\n",
      "Coherence Mean: 0.04248212277889252 GB\n",
      "Static Total: 2.3138364031910896 GB\n",
      "-----Dynamically calculated arrays-----\n",
      "TFR: 159.9576416015625 GB\n",
      "PSD: 26.65960693359375 GB\n",
      "Coherence: 2.5253729224205017 GB\n",
      "Coherence Mean (small): 0.010655581951141357 GB\n",
      "Dynamic Total: 189.1532770395279 GB\n",
      "---------------------------------\n",
      "Total: 191.46711344271898 GB\n",
      "Desired max: 191.5341453552246 GB\n",
      "---------------------------------\n",
      "Current free memory: 237.98957443237305 GB\n",
      "System total memory: 251.5341453552246 GB\n",
      "Data is too big for one pass!\n",
      "Data will be computed in batches of 152 epochs. Total batches: 4.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sfreq = 2048\n",
    "freqs = collect(14:250)\n",
    "zero_mean = true\n",
    "n_freqs = length(freqs)\n",
    "mt_bandwidth = 4\n",
    "n_taps = floor(Int, mt_bandwidth - 1)\n",
    "n_cycles = 7\n",
    "n_epochs, n_channels, n_times = size(data)\n",
    "\n",
    "batch_size = scale_dimensions(data, n_taps, freqs, sfreq, n_cycles, print=true, reserve_gb=60)\n",
    "total_batches = ceil(n_epochs / batch_size)\n",
    "if batch_size != n_epochs\n",
    "    println(\"Data is too big for one pass!\\nData will be computed in batches of $batch_size epochs. Total batches: $(total_batches)\")\n",
    "end\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
