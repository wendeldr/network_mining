{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can be computed with batches of 2 epochs\n",
      "total batches: 1.0\n",
      "--------------Static arrays--------------\n",
      "Data: 0.00015264004468917847 GB\n",
      "Weights: 0.00084686279296875 GB\n",
      "Ws: 0.0008460581302642822 GB\n",
      "FFT Ws: 0.003387451171875 GB\n",
      "FFT X: 0.0006103515625 GB\n",
      "Coherence Mean: 1.4901161193847656e-6 GB\n",
      "Static Total: 0.0058448538184165955 GB\n",
      "-----Dynamically calculated arrays-----\n",
      "TFR: 0.03387451171875 GB\n",
      "PSD: 0.005645751953125 GB\n",
      "Coherence: 5.513429641723633e-5 GB\n",
      "Coherence Mean (small): 0 GB\n",
      "Dynamic Total: 0.039575397968292236 GB\n",
      "---------------------------------\n",
      "Total: 0.04542025178670883 GB\n",
      "Desired max: 191.53417587280273 GB\n",
      "---------------------------------\n",
      "Current free memory: 236.57093048095703 GB\n",
      "System total memory: 251.53417587280273 GB\n",
      "Making tapers...\n",
      "Precomputing FFTs of tapers and data...\n",
      "Done!\n",
      "Preparing for computation...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "using FFTW\n",
    "using Statistics\n",
    "using JLD2\n",
    "using NPZ\n",
    "using ProgressMeter\n",
    "# \n",
    "\n",
    "function sinusoidal(a, f, sr, t, theta=0, DC=0)\n",
    "    delta_i = 1 / sr\n",
    "    f2pi = f * 2 * π\n",
    "    nu = [DC + (a * sin(f2pi * i * delta_i + theta)) for i in 0:(t-1)]\n",
    "    return nu\n",
    "end\n",
    "\n",
    "function tfr_estimate_size(n_epochs, n_channels, n_taps, n_freqs, n_times)\n",
    "    element_size = 16 # bytes for ComplexF64\n",
    "    total_elements = n_epochs * n_channels * n_taps * n_freqs * n_times\n",
    "    total_bytes = total_elements * element_size\n",
    "    total_gb = total_bytes / (1024^3) # Convert bytes to GB\n",
    "    return total_gb\n",
    "end\n",
    "\n",
    "function weights_estimate_size(n_taps, n_freqs, n_times)\n",
    "    element_size = 8 # bytes for Float64\n",
    "    total_elements = n_taps * n_freqs * n_times\n",
    "    total_bytes = total_elements * element_size\n",
    "    total_gb = total_bytes / (1024^3) # Convert bytes to GB\n",
    "    return total_gb\n",
    "end\n",
    "\n",
    "function Ws_estimate_size(n_taps, freqs, sfreq, n_cycles)\n",
    "    element_size = 16 # bytes for ComplexF64\n",
    "    total_elements = 0\n",
    "    for k = 1:n_freqs\n",
    "        f = freqs[k]\n",
    "        t_win = n_cycles / f\n",
    "        len_t = Int(ceil(t_win * sfreq))\n",
    "        total_elements += n_taps * len_t\n",
    "    end\n",
    "    total_bytes = total_elements * element_size\n",
    "    total_gb = total_bytes / (1024^3) # Convert bytes to GB\n",
    "    return total_gb\n",
    "end\n",
    "\n",
    "function fft_estimate_size(a, b, c)\n",
    "    element_size = 16 # bytes for ComplexF64\n",
    "    total_elements = a * b * c\n",
    "    total_bytes = total_elements * element_size\n",
    "    total_gb = total_bytes / (1024^3) # Convert bytes to GB\n",
    "    return total_gb\n",
    "end\n",
    "\n",
    "function psd_estimate_size(n_epochs, n_channels, n_freqs, n_times)\n",
    "    element_size = 8 # bytes for Float64\n",
    "    total_elements = n_epochs * n_channels * n_freqs * n_times\n",
    "    total_bytes = total_elements * element_size\n",
    "    total_gb = total_bytes / (1024^3) # Convert bytes to GB\n",
    "    return total_gb\n",
    "end\n",
    "\n",
    "function coh_estimate_size(n_epochs, n_channels, n_freqs)\n",
    "    element_size = 8 # bytes for Float64\n",
    "    total_elements = n_epochs * n_channels * n_channels * n_freqs\n",
    "    total_bytes = total_elements * element_size\n",
    "    total_gb = total_bytes / (1024^3) # Convert bytes to GB\n",
    "    return total_gb\n",
    "end\n",
    "\n",
    "function scale_dimensions(data, n_taps, freqs, sfreq, n_cycles; print=false, max_gb=0, reserve_gb=0)\n",
    "    system_mem = Sys.total_memory() / (1024^3)\n",
    "    if max_gb == 0\n",
    "        max_gb =  system_mem- reserve_gb # Leave X GB for other stuff\n",
    "    end\n",
    "    current_mem = Sys.free_memory() / (1024^3)\n",
    "    if current_mem <= max_gb\n",
    "        @warn \"Current free memory: $current_mem GB\\nDesired max: $max_gb GB\\nSystem total memory: $(system_mem) GB\\nMemory available is less than desired max!\\nAttempting to use available memory!\"\n",
    "        max_gb = current_mem - reserve_gb\n",
    "    end\n",
    "    if(max_gb <= 0)\n",
    "        error(\"Not enough memory available!\")\n",
    "    end\n",
    "    \n",
    "    n_epoch_org, n_channels, n_times = size(data)\n",
    "\n",
    "    n_freqs = length(freqs)\n",
    "    t_win = n_cycles / minimum(freqs)\n",
    "    max_len = Int(ceil(t_win * sfreq))\n",
    "    nfft = n_times + max_len - 1\n",
    "    nfft = next_fast_len(nfft)\n",
    "    \n",
    "    data_size = Base.summarysize(data) / (1024^3)\n",
    "    weights = weights_estimate_size(n_taps, n_freqs, n_times)\n",
    "    Ws = Ws_estimate_size(n_taps, freqs, sfreq, n_cycles)\n",
    "    fft_Ws = fft_estimate_size(n_taps, n_freqs, nfft)\n",
    "    fft_X = fft_estimate_size(n_epoch_org, n_channels, nfft)\n",
    "    coherence_mean = coh_estimate_size(n_epoch_org, n_channels, 1)\n",
    "    \n",
    "    current_mem = Sys.free_memory() / (1024^3)\n",
    "    \n",
    "    static_total = data_size + weights + Ws + fft_Ws + fft_X + coherence_mean\n",
    "    \n",
    "    if static_total >= max_gb || static_total >= current_mem\n",
    "        println(\"Static calculations will exceed memory!\")\n",
    "        println(\"---------------------------------\")\n",
    "        println(\"Current free memory: $current_mem GB\")\n",
    "        println(\"---------------------------------\")\n",
    "        println(\"Data: $(data_size) GB\")\n",
    "        println(\"Weights: $weights GB\")\n",
    "        println(\"Ws: $Ws GB\")\n",
    "        println(\"FFT Ws: $fft_Ws GB\")\n",
    "        println(\"FFT X: $fft_X GB\")\n",
    "        println(\"Coherence Mean: $coherence_mean GB\")\n",
    "        println(\"---------------------------------\")\n",
    "        println(\"Total: $static_total GB\")\n",
    "        println(\"Exceeds maximum memory limit of $max_gb GB or current free memory\")\n",
    "        error(\"Memory limit exceeded\")\n",
    "    end\n",
    "    n_epochs = copy(n_epoch_org)\n",
    "    tfr_size = tfr_estimate_size(n_epochs, n_channels, n_taps, n_freqs, n_times)\n",
    "    psd_per_epoch = psd_estimate_size(n_epochs, n_channels, n_freqs, n_times)\n",
    "    coherence = coh_estimate_size(n_epoch_org, n_channels, n_freqs)\n",
    "    coherence_mean_small = 0\n",
    "    \n",
    "    dynamic_total = tfr_size + psd_per_epoch + coherence + coherence_mean_small    \n",
    "    while dynamic_total + static_total >= max_gb && n_epochs > 0\n",
    "        n_epochs -= 1\n",
    "        tfr_size = tfr_estimate_size(n_epochs, n_channels, n_taps, n_freqs, n_times)\n",
    "        psd_per_epoch = psd_estimate_size(n_epochs, n_channels, n_freqs, n_times)\n",
    "        coherence = coh_estimate_size(n_epochs, n_channels, n_freqs)\n",
    "        coherence_mean_small = coh_estimate_size(n_epochs, n_channels, 1)\n",
    "        dynamic_total = tfr_size + psd_per_epoch + coherence + coherence_mean_small\n",
    "    end\n",
    "\n",
    "    if n_epochs == 0\n",
    "        current_mem = Sys.free_memory() / (1024^3)\n",
    "        println(\"Can not even compute one epoch with current memory!\")\n",
    "        println(\"---------------------------------\")\n",
    "        println(\"Current free memory: $current_mem GB\")\n",
    "        println(\"System total memory: $system_mem GB\")\n",
    "        println(\"--------------Static arrays--------------\")\n",
    "        println(\"Data: $(data_size) GB\")\n",
    "        println(\"Weights: $weights GB\")\n",
    "        println(\"Ws: $Ws GB\")\n",
    "        println(\"FFT Ws: $fft_Ws GB\")\n",
    "        println(\"FFT X: $fft_X GB\")\n",
    "        println(\"Coherence Mean: $coherence_mean GB\")\n",
    "        println(\"Static Total: $static_total GB\")\n",
    "        println(\"-----Dynamically calculated arrays-----\")\n",
    "        println(\"TFR: $tfr_size GB\")\n",
    "        println(\"PSD: $psd_per_epoch GB\")\n",
    "        println(\"Coherence: $coherence GB\")\n",
    "        println(\"Coherence Mean (small): $coherence_mean_small GB\")\n",
    "        println(\"Dynamic Total: $dynamic_total GB\")\n",
    "        println(\"---------------------------------\")\n",
    "        println(\"Total: $dynamic_total + $static_total GB\")\n",
    "        println(\"Exceeds maximum memory limit of $max_gb GB\")\n",
    "        error(\"Memory limit exceeded\")\n",
    "    end\n",
    "\n",
    "\n",
    "\n",
    "    if print\n",
    "        current_mem = Sys.free_memory() / (1024^3)\n",
    "        println(\"Can be computed with batches of $n_epochs epochs\")\n",
    "        println(\"total batches: $(ceil(n_epoch_org/n_epochs))\")\n",
    "        println(\"--------------Static arrays--------------\")\n",
    "        println(\"Data: $(data_size) GB\")\n",
    "        println(\"Weights: $weights GB\")\n",
    "        println(\"Ws: $Ws GB\")\n",
    "        println(\"FFT Ws: $fft_Ws GB\")\n",
    "        println(\"FFT X: $fft_X GB\")\n",
    "        println(\"Coherence Mean: $coherence_mean GB\")\n",
    "        println(\"Static Total: $static_total GB\")\n",
    "        println(\"-----Dynamically calculated arrays-----\")\n",
    "        println(\"TFR: $tfr_size GB\")\n",
    "        println(\"PSD: $psd_per_epoch GB\")\n",
    "        println(\"Coherence: $coherence GB\")\n",
    "        println(\"Coherence Mean (small): $coherence_mean_small GB\")\n",
    "        println(\"Dynamic Total: $dynamic_total GB\")\n",
    "        println(\"---------------------------------\")\n",
    "        println(\"Total: $(dynamic_total+static_total) GB\")\n",
    "        println(\"Desired max: $max_gb GB\")\n",
    "        println(\"---------------------------------\")        \n",
    "        println(\"Current free memory: $current_mem GB\")\n",
    "        println(\"System total memory: $system_mem GB\")\n",
    "    end\n",
    "    return n_epochs\n",
    "end\n",
    "\n",
    "function tril_indices(n)::Array{Tuple{Int,Int},1}\n",
    "    pairs = Array{Tuple{Int,Int},1}(undef, n * (n - 1) ÷ 2)\n",
    "    q = 1\n",
    "    for x in 1:n\n",
    "        for y in (x+1):n\n",
    "            pairs[q] = (x, y)\n",
    "            q += 1\n",
    "        end\n",
    "    end\n",
    "    return pairs\n",
    "end\n",
    "\n",
    "\n",
    "function next_fast_len(target::Int)::Int\n",
    "    \"\"\"\n",
    "    Find the next fast size of input data to `fft`, for zero-padding, etc.\n",
    "\n",
    "    Returns the next composite of the prime factors 2, 3, and 5 which is\n",
    "    greater than or equal to `target`. (These are also known as 5-smooth\n",
    "    numbers, regular numbers, or Hamming numbers.)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Int\n",
    "        Length to start searching from. Must be a positive integer.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : Int\n",
    "        The first 5-smooth number greater than or equal to `target`.\n",
    "    \"\"\"\n",
    "    # Precomputed Hamming numbers (5-smooth numbers) for quick lookup\n",
    "    hams = [\n",
    "        8, 9, 10, 12, 15, 16, 18, 20, 24, 25, 27, 30, 32, 36, 40, 45, 48, 50,\n",
    "        54, 60, 64, 72, 75, 80, 81, 90, 96, 100, 108, 120, 125, 128, 135, 144,\n",
    "        150, 160, 162, 180, 192, 200, 216, 225, 240, 243, 250, 256, 270, 288,\n",
    "        300, 320, 324, 360, 375, 384, 400, 405, 432, 450, 480, 486, 500, 512,\n",
    "        540, 576, 600, 625, 640, 648, 675, 720, 729, 750, 768, 800, 810, 864,\n",
    "        900, 960, 972, 1000, 1024, 1080, 1125, 1152, 1200, 1215, 1250, 1280,\n",
    "        1296, 1350, 1440, 1458, 1500, 1536, 1600, 1620, 1728, 1800, 1875, 1920,\n",
    "        1944, 2000, 2025, 2048, 2160, 2187, 2250, 2304, 2400, 2430, 2500, 2560,\n",
    "        2592, 2700, 2880, 2916, 3000, 3072, 3125, 3200, 3240, 3375, 3456, 3600,\n",
    "        3645, 3750, 3840, 3888, 4000, 4050, 4096, 4320, 4374, 4500, 4608, 4800,\n",
    "        4860, 5000, 5120, 5184, 5400, 5625, 5760, 5832, 6000, 6075, 6144, 6250,\n",
    "        6400, 6480, 6561, 6750, 6912, 7200, 7290, 7500, 7680, 7776, 8000, 8100,\n",
    "        8192, 8640, 8748, 9000, 9216, 9375, 9600, 9720, 10000\n",
    "    ]\n",
    "\n",
    "    if target <= 6\n",
    "        return target\n",
    "    end\n",
    "\n",
    "    # Check if target is already a power of 2\n",
    "    if (target & (target - 1)) == 0\n",
    "        return target\n",
    "    end\n",
    "\n",
    "    # Quick lookup for small sizes\n",
    "    if target <= hams[end]\n",
    "        idx = searchsortedfirst(hams, target)\n",
    "        return hams[idx]\n",
    "    end\n",
    "\n",
    "    # Function to compute the bit length of an integer\n",
    "    bit_length(x::Int) = x <= 0 ? 0 : floor(Int, log2(x)) + 1\n",
    "\n",
    "    match = typemax(Int)  # Initialize with maximum possible integer\n",
    "    p5 = 1\n",
    "    while p5 < target\n",
    "        p35 = p5\n",
    "        while p35 < target\n",
    "            # Ceiling integer division\n",
    "            quotient = cld(target, p35)\n",
    "            p2 = 2^bit_length(quotient - 1)\n",
    "            N = p2 * p35\n",
    "            if N == target\n",
    "                return N\n",
    "            elseif N < match\n",
    "                match = N\n",
    "            end\n",
    "            p35 *= 3\n",
    "            if p35 == target\n",
    "                return p35\n",
    "            end\n",
    "        end\n",
    "        if p35 < match\n",
    "            match = p35\n",
    "        end\n",
    "        p5 *= 5\n",
    "        if p5 == target\n",
    "            return p5\n",
    "        end\n",
    "    end\n",
    "    if p5 < match\n",
    "        match = p5\n",
    "    end\n",
    "    return match\n",
    "end\n",
    "\n",
    "### Tapers\n",
    "function _extend(M::Int, sym::Bool)::Tuple{Int,Bool}\n",
    "    # Extend window by 1 sample if needed for DFT-even symmetry\n",
    "    if !sym\n",
    "        return M + 1, true\n",
    "    else\n",
    "        return M, false\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function _fftautocorr(x::AbstractMatrix{<:Float64})::Array{Float64, 2}\n",
    "    \"\"\"\n",
    "    tested vs python:\n",
    "    isapprox(x_fft, py_x_fft, atol=1e-12) == true\n",
    "    isapprox(py_cxy, cxy, atol=1e-12) == true\n",
    "    \"\"\"\n",
    "    N = size(x, 2)\n",
    "    use_N = next_fast_len(2 * N - 1)\n",
    "    padded = zeros(Float64, size(x, 1), use_N)\n",
    "    padded[:, 1:N] .= x\n",
    "    plan = plan_rfft(padded, 2)\n",
    "    x_fft = plan * padded\n",
    "    cxy = irfft(x_fft .* conj.(x_fft), use_N, 2)[:, 1:N]\n",
    "    return cxy\n",
    "end\n",
    "\n",
    "function py_dpss(M::Int, NW::Float64, normalization_type::Int, Kmax::Int; sym::Bool=true)::Tuple{Array{Complex{Float64},2},Union{Array{Float64,1},Float64}}\n",
    "    \"\"\"\n",
    "    Compute the Discrete Prolate Spheroidal Sequences (DPSS).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    M : Int\n",
    "        Window length.\n",
    "    NW : Float64\n",
    "        Standardized half bandwidth corresponding to 2*NW = BW/f0 = BW*M*dt\n",
    "        where dt is taken as 1.\n",
    "    normalization_type : Int\n",
    "        Normalization of the DPSS windows. Must be one of 1, 2, or 3.\n",
    "        1: No normalization.\n",
    "        2: Approximate normalization.\n",
    "        3: Subsample normalization.\n",
    "    Kmax : Int\n",
    "        Number of DPSS windows to return. Must be less than or equal to M and greater than 0.\n",
    "        If 1, return only a single window of shape (M,)\n",
    "        instead of an array of windows of shape (Kmax, M).\n",
    "    sym : Bool, optional\n",
    "        When true (default), generates a symmetric window, for use in filter design.\n",
    "        When false, generates a periodic window, for use in spectral analysis.\n",
    "\n",
    "    return_ratios : Bool, optional\n",
    "        If true, also return the concentration ratios in addition to the windows.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    windows : Array{Float64, 2} or Array{Float64, 1}\n",
    "        The DPSS windows. Will be 1D if `Kmax` is nothing.\n",
    "    ratios : Array{Float64, 1} or Float64, optional\n",
    "        The concentration ratios for the windows. Only returned if\n",
    "        `return_ratios` evaluates to true. Will be scalar if `Kmax` is nothing.\n",
    "    \"\"\"\n",
    "    known_norms = (1, 2, 3)\n",
    "    if normalization_type ∉ known_norms\n",
    "        error(\"normalization_type must be one of $known_norms, got $normalization_type\")\n",
    "    end\n",
    "    if Kmax === 1\n",
    "        singleton = true\n",
    "    else\n",
    "        singleton = false\n",
    "    end\n",
    "    if !(0 < Kmax <= M)\n",
    "        error(\"Kmax must be greater than 0 and less than or equal to M\")\n",
    "    end\n",
    "    if NW >= M / 2.0\n",
    "        error(\"NW must be less than M/2.\")\n",
    "    end\n",
    "    if NW <= 0\n",
    "        error(\"NW must be positive\")\n",
    "    end\n",
    "\n",
    "    M, needs_trunc = _extend(M, sym)\n",
    "    W = NW / M\n",
    "    nidx = collect(0:M-1)\n",
    "    d = ((M - 1 .- 2 .* nidx) ./ 2.0) .^ 2 .* cos.(2pi * W)\n",
    "    e = nidx[2:end] .* (M .- nidx[2:end]) ./ 2.0\n",
    "    # Use SymTridiagonal for efficient eigenvalue computation\n",
    "    T = SymTridiagonal(d, e)\n",
    "    evals = eigvals(T, M-Kmax+1:M);\n",
    "    evecs = eigvecs(T, evals);\n",
    "    # Extract the largest Kmax eigenvalues and eigenvectors\n",
    "    windows = evecs[:, end:-1:1]'\n",
    "    # Correct sign conventions\n",
    "    fix_even = sum(windows[1:2:end, :], dims=2) .< 0\n",
    "    windows[1:2:end, :][fix_even[:, 1], :] .*= -1\n",
    "\n",
    "    # # Correct signs for even-indexed windows\n",
    "    thresh = max(1e-7, 1.0 / M)\n",
    "    for (i, w) in enumerate(eachrow(windows[2:2:end, :]))\n",
    "        idx = findfirst(x -> x^2 > thresh, w)\n",
    "        if idx !== nothing && w[idx] < 0\n",
    "            windows[2i, :] *= -1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Compute concentration ratios\n",
    "    dpss_rxx = _fftautocorr(windows)\n",
    "    r = 4 * W * sinc.(2 * W .* (nidx))\n",
    "    r[1] = 2 * W\n",
    "    ratios = dpss_rxx * r\n",
    "\n",
    "    if singleton\n",
    "        ratios = ratios[1]\n",
    "    end\n",
    "    # Apply normalization if needed\n",
    "    if normalization_type != 1\n",
    "        max_abs = maximum(abs, windows)\n",
    "        windows ./= max_abs\n",
    "        if iseven(M)\n",
    "            if normalization_type == 2\n",
    "                correction = M^2 / (M^2 + NW)\n",
    "            elseif normalization_type == 3\n",
    "                s = rfft(windows[1, :])\n",
    "                shift = -(1 - 1.0 / M) .* (1:Int(M / 2))\n",
    "                s[2:end] .*= 2 .* exp.(-im * π .* shift)\n",
    "                correction = M / sum(real(s))\n",
    "            end\n",
    "            windows .*= correction\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if needs_trunc\n",
    "        windows = windows[:, 1:end-1]\n",
    "    end\n",
    "    if singleton\n",
    "        windows = windows[1, :]\n",
    "    end\n",
    "    return windows, ratios\n",
    "end\n",
    "\n",
    "function compute_tapers(N::Int, n_taps::Int, freqs::AbstractArray{<:Real}, mt_bandwidth::Real, n_cycles::Int, sfreq::Int; zero_mean::Bool=true)::Tuple{Matrix{Vector{ComplexF64}},Array{Float64,3}}\n",
    "    n_freqs = length(freqs)\n",
    "    weights = Array{Float64,3}(undef, n_taps, n_freqs, N)\n",
    "    Ws = Matrix{Vector{ComplexF64}}(undef, n_taps, n_freqs)\n",
    "    sp5 = sqrt(0.5)\n",
    "    # Loop over frequencies first\n",
    "    Threads.@threads for k in eachindex(freqs)\n",
    "        f = freqs[k]\n",
    "        t_win = n_cycles / f\n",
    "        len_t = Int(ceil(t_win * sfreq))\n",
    "\n",
    "        t = collect(0:1/sfreq:t_win-(t_win % (1 / sfreq) == 0 ? 1 / sfreq : 0)) # exclude last value if it fits exactly\n",
    "        t_centered = t .- t_win / 2.0\n",
    "\n",
    "        # Precompute oscillation and taper\n",
    "        oscillation = exp.(2.0 * im * pi * f .* t_centered)\n",
    "\n",
    "        taper, e = py_dpss(len_t, mt_bandwidth / 2, 1, n_taps, sym=false)\n",
    "        weights[:, k, :] .= sqrt.(e)\n",
    "\n",
    "        for m = 1:n_taps\n",
    "            # Use @view to avoid copying taper column\n",
    "            Wk = oscillation .* @view taper[m, :]\n",
    "\n",
    "            if zero_mean  # To make it zero mean\n",
    "                real_offset = mean(Wk)\n",
    "                Wk .-= real_offset\n",
    "            end\n",
    "\n",
    "            # Normalize Wk\n",
    "            Wk /= sp5 * norm(Wk)\n",
    "\n",
    "            # Store Wk in preallocated Ws\n",
    "            Ws[m, k] = Wk\n",
    "        end\n",
    "    end\n",
    "    return Ws, weights\n",
    "end\n",
    "### end tapers\n",
    "\n",
    "\n",
    "function _get_nfft(Ws::Matrix{Vector{ComplexF64}}, X::AbstractArray{<:Float64})::Int\n",
    "    max_len = maximum([length(Wk) for Wk in Ws])\n",
    "    n = last(size(X))\n",
    "    nfft = n + max_len - 1\n",
    "    # @show nfft\n",
    "    nfft = next_fast_len(nfft)\n",
    "    return nfft\n",
    "end\n",
    "\n",
    "function coh(s_xx::AbstractMatrix{Float64}, s_yy::AbstractMatrix{Float64}, s_xy::AbstractMatrix{ComplexF64})::Array{Float64}\n",
    "    # Compute the numerator: absolute value of the mean of s_xy along the last dimension\n",
    "    con_num = abs.(mean(s_xy, dims=ndims(s_xy)))\n",
    "\n",
    "    # Compute the denominator: square root of the product of means of s_xx and s_yy along the last dimension\n",
    "    con_den = sqrt.(mean(s_xx, dims=ndims(s_xx)) .* mean(s_yy, dims=ndims(s_yy)))\n",
    "\n",
    "    # Calculate coherence as the element-wise division of numerator by denominator\n",
    "    coh = con_num ./ con_den\n",
    "    return coh\n",
    "end\n",
    "\n",
    "\n",
    "# Precompute FFTs of Ws\n",
    "function precompute_fft_Ws(Ws, nfft)\n",
    "    n_taps, n_freqs = size(Ws)\n",
    "    fft_Ws = zeros(ComplexF64, n_taps, n_freqs, nfft) # preallocated padded array\n",
    "    \n",
    "    # tried threading but it was slightly slower\n",
    "    for taper_idx = 1:n_taps\n",
    "        for freq_idx = 1:n_freqs\n",
    "            # Ws are different lengths\n",
    "            fft_Ws[taper_idx, freq_idx, 1:length(Ws[taper_idx, freq_idx])] .= Ws[taper_idx, freq_idx]\n",
    "        end\n",
    "    end\n",
    "    # plan fft!\n",
    "    p = plan_fft!(fft_Ws, 3)\n",
    "    return p * fft_Ws\n",
    "end\n",
    "\n",
    "# Precompute FFTs of X\n",
    "function precompute_fft_X(X, nfft)\n",
    "    n_epochs, n_channels, n_times = size(X)\n",
    "    fft_X = zeros(ComplexF64,n_epochs, n_channels, nfft)\n",
    "    fft_X[:,:,1:n_times] .= data\n",
    "    p = plan_fft!(fft_X, 3)\n",
    "    return p * fft_X\n",
    "end\n",
    "\n",
    "function compute_tfr!(tfr::Array{ComplexF64, 5}, fft_X::Array{ComplexF64, 3}, fft_Ws::Array{ComplexF64, 3}, Ws_lengths::Array{Int64, 2})\n",
    "    batch_size, n_channels, nfft = size(fft_X)\n",
    "    n_taps, n_freqs, _ = size(fft_Ws)\n",
    "    _, _, _, _, n_times = size(tfr)\n",
    "    \n",
    "    # Precompute sizes, start_indices, and end_indices\n",
    "    sizes = n_times .+ Ws_lengths .- 1\n",
    "    start_indices = floor.(Int, (sizes .- n_times) ./ 2) .+ 1\n",
    "    end_indices = start_indices .+ n_times .- 1\n",
    "    \n",
    "    nthreads = Threads.nthreads()\n",
    "    temp_arrays = [Array{ComplexF64}(undef, batch_size, n_channels, nfft) for _ in 1:nthreads]\n",
    "    fft_plans = [plan_ifft!(temp_arrays[i], 3) for i in 1:nthreads]\n",
    "    \n",
    "    # Thread over frequencies\n",
    "    @inbounds @showprogress desc=\"Computing TFRs\" Threads.@threads for freq_idx = 1:n_freqs\n",
    "        thread_id = Threads.threadid()\n",
    "        temp = temp_arrays[thread_id]\n",
    "        ifft_plan = fft_plans[thread_id]\n",
    "        \n",
    "        # Loop over tapers\n",
    "        for taper_idx = 1:n_taps\n",
    "            fft_W = fft_Ws[taper_idx, freq_idx, :]  # Current fft_W\n",
    "            Ws_length = Ws_lengths[taper_idx, freq_idx]\n",
    "            ret_size = n_times + Ws_length - 1\n",
    "            \n",
    "            # Compute start and end indices for slicing\n",
    "            start = start_indices[taper_idx, freq_idx]\n",
    "            end_time = end_indices[taper_idx, freq_idx]\n",
    "            \n",
    "            # Compute the product and inverse FFT in-place\n",
    "            temp .= fft_X .* reshape(fft_W, 1, 1, nfft)  # Broadcasting over first two dims\n",
    "            temp .= ifft_plan * temp  # In-place inverse FFT\n",
    "            \n",
    "            # Assign the centered result to tfr\n",
    "            tfr[:, :, taper_idx, freq_idx, :] .= temp[:, :, start:end_time]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return tfr\n",
    "end\n",
    "\n",
    "function compute_psd(batch_size::Int, n_channels::Int, n_freqs::Int, n_times::Int, tfrs::Array{ComplexF64,5}, weights::Array{Float64,3}, normalization::Array{Float64, 3})::Array{Float64,4}\n",
    "    psd_per_epoch = Array{Float64,4}(undef, batch_size, n_channels, n_freqs, n_times)\n",
    "    @showprogress desc = \"Computing epoch's PSD...\" Threads.@threads for idx = 1:(batch_size*n_channels)\n",
    "        # Compute epoch_idx and c_idx from idx\n",
    "        epoch_idx = div(idx - 1, n_channels) + 1\n",
    "        c_idx = mod(idx - 1, n_channels) + 1\n",
    "\n",
    "        # Perform the element-wise multiplication with broadcasting\n",
    "        psd = weights .* @view tfrs[epoch_idx, c_idx, :, :, :]\n",
    "\n",
    "        # Square magnitude (complex conjugate multiplication)\n",
    "        psd .= psd .* conj(psd)\n",
    "\n",
    "        # Sum across the first dimension (tapers)\n",
    "        psd = sum(real(psd), dims=1)\n",
    "\n",
    "        # Apply the normalization\n",
    "        psd .= psd .* normalization\n",
    "\n",
    "        # Update the psd_per_epoch array\n",
    "        psd_per_epoch[epoch_idx, c_idx, :, :] .= psd[1, :, :]\n",
    "    end\n",
    "    return psd_per_epoch\n",
    "end\n",
    "\n",
    "function compute_coh_mean(epochs::Int, n_channels::Int, n_freqs::Int, n_pairs::Int, tfrs::Array{ComplexF64,5}, psd_per_epoch::Array{Float64,4}, weights::Array{Float64,3}, normalization::Array{Float64, 3})::Array{Float64,4}\n",
    "    coherence = Array{Float64,4}(undef, epochs, n_channels, n_channels, n_freqs)\n",
    "    @showprogress desc = \"Computing Coherence...\" Threads.@threads for idx in 1:epochs*n_pairs\n",
    "        # Calculate the epoch index and pair index\n",
    "        epoch_idx = div(idx - 1, n_pairs) + 1\n",
    "        pair_idx = mod(idx - 1, n_pairs) + 1\n",
    "        x, y = pairs[pair_idx]\n",
    "        # println(\"Epoch: $epoch_idx, Pair: ($x, $y)\")\n",
    "        # Now perform your operations\n",
    "        w_x = @view tfrs[epoch_idx, x, :, :, :]\n",
    "        w_y = @view tfrs[epoch_idx, y, :, :, :]\n",
    "        s_xy = sum(weights .* w_x .* conj(weights .* w_y), dims=1)  # sum over tapers\n",
    "        s_xy = s_xy .* normalization\n",
    "\n",
    "        s_xx = @view psd_per_epoch[epoch_idx, x, :, :]\n",
    "        s_yy = @view psd_per_epoch[epoch_idx, y, :, :]\n",
    "        coh_value = coh(s_xx, s_yy, s_xy[1, :, :])\n",
    "\n",
    "        # Copy to symmetric position\n",
    "        coherence[epoch_idx, y, x, :] .= coh_value\n",
    "    end\n",
    "    return mean(coherence, dims=ndims(coherence))\n",
    "end\n",
    "\n",
    "# t = 32\n",
    "# sr = 32\n",
    "# f = 2\n",
    "\n",
    "# v = sinusoidal(10, f, sr, t * 4, 0)\n",
    "# w = sinusoidal(10, f, sr, t * 4, π / 4)\n",
    "# y = sinusoidal(10, f, sr, t * 4, π / 2)\n",
    "# z = sinusoidal(10, f, sr, t * 4, π)\n",
    "\n",
    "# data = Array{Float64}(undef, 2, 4, 128)\n",
    "\n",
    "# data[1, :, :] = hcat(v, w, y, z)'\n",
    "# data[2, :, :] = hcat(-v, -w, -y, -z)';\n",
    "\n",
    "# freqs = collect(2:15) # inclusive of end \n",
    "# n_freqs = length(freqs)\n",
    "# mt_bandwidth = 4\n",
    "# n_taps = floor(Int, mt_bandwidth - 1)\n",
    "# n_cycles = 7\n",
    "# sfreq = 32\n",
    "# zero_mean = true\n",
    "\n",
    "\n",
    "outputpath = \"/media/dan/Data/git/network_mining/connectivity/julia_test/\"\n",
    "data = npzread(\"/media/dan/Data/git/network_mining/connectivity/julia_test/034_input.npy\")\n",
    "data = data[1:2, 1:10, :]\n",
    "\n",
    "sfreq = 2048\n",
    "freqs = collect(14:50)\n",
    "zero_mean = true\n",
    "n_freqs = length(freqs)\n",
    "mt_bandwidth = 4\n",
    "n_taps = floor(Int, mt_bandwidth - 1)\n",
    "n_cycles = 7\n",
    "n_epochs, n_channels, n_times = size(data)\n",
    "\n",
    "batch_size = scale_dimensions(data, n_taps, freqs, sfreq, n_cycles, print=true, reserve_gb=60)\n",
    "total_batches = ceil(n_epochs / batch_size)\n",
    "if batch_size != n_epochs\n",
    "    println(\"Data is too big for one pass!\\nData will be computed in batches of $batch_size epochs. Total batches: $(total_batches)\")\n",
    "end\n",
    "\n",
    "println(\"Making tapers...\")\n",
    "Ws, weights = compute_tapers(n_times, n_taps, freqs, mt_bandwidth, n_cycles, sfreq)\n",
    "\n",
    "normalization = 2 ./ sum(real(weights .* conj(weights)), dims=1);\n",
    "nfft = _get_nfft(Ws, data)\n",
    "\n",
    "println(\"Precomputing FFTs of tapers and data...\")\n",
    "fft_Ws = precompute_fft_Ws(Ws, nfft);\n",
    "fft_X = precompute_fft_X(data, nfft);\n",
    "println(\"Done!\")\n",
    "\n",
    "# save(joinpath(outputpath, \"034_pretasks.jld2\"), \"Ws\", Ws, \"weights\", weights, \"fft_Ws\", fft_Ws, \"fft_X\", fft_X, \"normalization\", normalization)\n",
    "\n",
    "Ws_lengths = [length(Wk) for Wk in Ws]\n",
    "\n",
    "println(\"Preparing for computation...\")\n",
    "pairs = tril_indices(n_channels)\n",
    "n_pairs = length(pairs)\n",
    "b=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mComputing TFRs 100%|█████████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "tfr = Array{ComplexF64,5}(undef, batch_size, n_channels, n_taps, n_freqs, n_times);\n",
    "compute_tfr!(tfr, fft_X, fft_Ws, Ws_lengths);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_psd1! (generic function with 2 methods)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_psd1!(psd_per_epoch::Array{Float64,4}, tfrs::Array{ComplexF64,5}, weights::Array{Float64,3}, normalization::Array{Float64, 2})::Array{Float64,4}\n",
    "    batch_size, n_channels, n_tapers, n_freqs, n_times = size(tfrs)\n",
    "\n",
    "    nthreads = Threads.nthreads()\n",
    "    psd_arrays = [zeros(ComplexF64, n_tapers, n_freqs, n_times) for _ in 1:nthreads]\n",
    "    psd_sums = [zeros(Float64, n_freqs, n_times) for _ in 1:nthreads]\n",
    "\n",
    "    Threads.@threads for idx = 1:(batch_size * n_channels)\n",
    "        thread_id = Threads.threadid()\n",
    "        psd = psd_arrays[thread_id]\n",
    "        psd_sum = psd_sums[thread_id]\n",
    "\n",
    "        # Compute epoch_idx and channel_idx from idx\n",
    "        epoch_idx = div(idx - 1, n_channels) + 1\n",
    "        c_idx = mod(idx - 1, n_channels) + 1\n",
    "\n",
    "        # Extract the current tfr slice\n",
    "        tfr_view = @view tfrs[epoch_idx, c_idx, :, :, :]\n",
    "\n",
    "        # Perform the element-wise multiplication\n",
    "        @. psd = weights * tfr_view\n",
    "\n",
    "        # Compute the squared magnitude\n",
    "        @. psd = psd * conj(psd)\n",
    "\n",
    "        # Sum across the first dimension (tapers)\n",
    "        psd_sum .= 0.0\n",
    "        @inbounds for t = 1:n_tapers\n",
    "            @views psd_sum .= psd_sum .+ real(psd[t, :, :])\n",
    "        end\n",
    "\n",
    "        # Apply the normalization\n",
    "        @. psd_sum = psd_sum * normalization\n",
    "\n",
    "        # Update the psd_per_epoch array\n",
    "        psd_per_epoch[epoch_idx, c_idx, :, :] .= psd_sum\n",
    "    end\n",
    "    return psd_per_epoch\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_psd_vectorized! (generic function with 2 methods)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_psd_vectorized!(psd_per_epoch::Array{Float64,4}, tfrs::Array{ComplexF64,5},  weights::Array{Float64,3}, normalization::Array{Float64, 2})::Array{Float64,4}\n",
    "    batch_size, n_channels, n_tapers, n_freqs, n_times = size(tfrs)\n",
    "    \n",
    "    # Reshape for broadcasting\n",
    "    weights_reshaped = reshape(weights, 1, 1, n_tapers, n_freqs, n_times)\n",
    "    normalization_reshaped = reshape(normalization, 1, 1, n_freqs, n_times)\n",
    "    \n",
    "    # Compute the weighted tfrs\n",
    "    psd = weights_reshaped .* tfr  # size: (batch_size, n_channels, n_tapers, n_freqs, n_times)\n",
    "\n",
    "    # Compute the squared magnitude\n",
    "    psd .= real(psd .* conj(psd))\n",
    "\n",
    "    # Sum over tapers\n",
    "    psd_per_epoch .= dropdims(sum(psd, dims=3),dims=3)  # size: (batch_size, n_channels, 1, n_freqs, n_times)\n",
    "\n",
    "\n",
    "    # Apply normalization\n",
    "    psd_per_epoch .= psd_per_epoch .* normalization_reshaped  # broadcasting over batch_size and n_channels\n",
    "\n",
    "    return psd_per_epoch\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = compute_psd(batch_size, n_channels, n_freqs, n_times, tfr, weights, normalization)\n",
    "psd_per_epoch = Array{Float64,4}(undef, batch_size, n_channels, n_freqs, n_times);\n",
    "small_norm = dropdims(normalization; dims=1)\n",
    "b = compute_psd1!(psd_per_epoch, tfr, weights, small_norm);\n",
    "psd_per_epoch = Array{Float64,4}(undef, batch_size, n_channels, n_freqs, n_times);\n",
    "c = compute_psd_vectorized!(psd_per_epoch, tfr, weights, small_norm);\n",
    "a == b == c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mComputing epoch's PSD... 100%|███████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mComputing epoch's PSD... 100%|███████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mComputing epoch's PSD... 100%|███████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mComputing epoch's PSD... 100%|███████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mComputing epoch's PSD... 100%|███████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mComputing epoch's PSD... 100%|███████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 86 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m43.081 ms\u001b[22m\u001b[39m … \u001b[35m195.489 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m 0.00% … 74.31%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m51.240 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m 4.68%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m58.110 ms\u001b[22m\u001b[39m ± \u001b[32m 25.831 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m12.93% ± 13.98%\n",
       "\n",
       "  \u001b[39m▄\u001b[39m▁\u001b[39m▇\u001b[39m█\u001b[34m▃\u001b[39m\u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▆\u001b[39m▆\u001b[32m▅\u001b[39m\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m \u001b[39m▁\n",
       "  43.1 ms\u001b[90m         Histogram: frequency by time\u001b[39m          173 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m104.07 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m330\u001b[39m."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark compute_psd(batch_size, n_channels, n_freqs, n_times, tfr, weights, normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 149 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m29.578 ms\u001b[22m\u001b[39m … \u001b[35m40.739 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 26.14%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m34.547 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m2.46%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m33.605 ms\u001b[22m\u001b[39m ± \u001b[32m 2.935 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m1.93% ±  2.53%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m▆\u001b[39m▃\u001b[39m \u001b[39m \u001b[39m \u001b[39m█\u001b[39m▆\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[34m \u001b[39m\u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m▆\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▃\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▃\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▁\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[32m▃\u001b[39m\u001b[39m▃\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[34m▇\u001b[39m\u001b[39m▃\u001b[39m▄\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m▄\u001b[39m█\u001b[39m█\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▄\u001b[39m▆\u001b[39m▄\u001b[39m \u001b[39m▃\n",
       "  29.6 ms\u001b[90m         Histogram: frequency by time\u001b[39m        39.2 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m19.37 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m197\u001b[39m."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark compute_psd1!(psd_per_epoch, tfr, weights, small_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 43 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m 95.480 ms\u001b[22m\u001b[39m … \u001b[35m257.560 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m 0.00% … 62.98%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m107.573 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m 8.43%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m118.455 ms\u001b[22m\u001b[39m ± \u001b[32m 38.468 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m16.96% ± 15.41%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m█\u001b[34m▆\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▃\u001b[39m▆\u001b[39m▄\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▇\u001b[39m▃\u001b[39m▆\u001b[39m▁\u001b[32m▁\u001b[39m\u001b[39m▄\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▄\u001b[39m \u001b[39m▁\n",
       "  95.5 ms\u001b[90m          Histogram: frequency by time\u001b[39m          258 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m132.97 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m34\u001b[39m."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark compute_psd_vectorized!(psd_per_epoch, tfr, weights, small_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
